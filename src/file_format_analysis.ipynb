{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# File format analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to approach the project with a broader scope, we have not only decided to focus on the data analysis component but also some aspects regarding the data management of a possible data exploitation process this project could be encapsulated into.\n",
    "\n",
    "We have defined different data zones to store the different steps of the data analysis process. Although we want the solution to be very general to fit most cases, we will also try to propose suitable approach to storing this data.\n",
    "\n",
    "We have seen that lots of the values to be stored are repeated (i.e. the measurement unit of energy which is the same each row), so it makes sense to use some kind of file format that uses compression. For this reason we have decided to test parquet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StartTime</th>\n",
       "      <th>EndTime</th>\n",
       "      <th>AreaID</th>\n",
       "      <th>UnitName</th>\n",
       "      <th>PsrType</th>\n",
       "      <th>quantity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2021-12-31T23:45+00:00Z</td>\n",
       "      <td>2022-01-01T00:00+00:00Z</td>\n",
       "      <td>10Y1001A1001A83F</td>\n",
       "      <td>MAW</td>\n",
       "      <td>B18</td>\n",
       "      <td>5688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2022-01-01T00:00+00:00Z</td>\n",
       "      <td>2022-01-01T00:15+00:00Z</td>\n",
       "      <td>10Y1001A1001A83F</td>\n",
       "      <td>MAW</td>\n",
       "      <td>B18</td>\n",
       "      <td>5795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2022-01-01T00:15+00:00Z</td>\n",
       "      <td>2022-01-01T00:30+00:00Z</td>\n",
       "      <td>10Y1001A1001A83F</td>\n",
       "      <td>MAW</td>\n",
       "      <td>B18</td>\n",
       "      <td>5775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2022-01-01T00:30+00:00Z</td>\n",
       "      <td>2022-01-01T00:45+00:00Z</td>\n",
       "      <td>10Y1001A1001A83F</td>\n",
       "      <td>MAW</td>\n",
       "      <td>B18</td>\n",
       "      <td>5843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01T00:45+00:00Z</td>\n",
       "      <td>2022-01-01T01:00+00:00Z</td>\n",
       "      <td>10Y1001A1001A83F</td>\n",
       "      <td>MAW</td>\n",
       "      <td>B18</td>\n",
       "      <td>5699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 StartTime                  EndTime            AreaID  \\\n",
       "0  2021-12-31T23:45+00:00Z  2022-01-01T00:00+00:00Z  10Y1001A1001A83F   \n",
       "1  2022-01-01T00:00+00:00Z  2022-01-01T00:15+00:00Z  10Y1001A1001A83F   \n",
       "2  2022-01-01T00:15+00:00Z  2022-01-01T00:30+00:00Z  10Y1001A1001A83F   \n",
       "3  2022-01-01T00:30+00:00Z  2022-01-01T00:45+00:00Z  10Y1001A1001A83F   \n",
       "4  2022-01-01T00:45+00:00Z  2022-01-01T01:00+00:00Z  10Y1001A1001A83F   \n",
       "\n",
       "  UnitName PsrType  quantity  \n",
       "0      MAW     B18      5688  \n",
       "1      MAW     B18      5795  \n",
       "2      MAW     B18      5775  \n",
       "3      MAW     B18      5843  \n",
       "4      MAW     B18      5699  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\"\n",
    "\n",
    "filepath = '../data/test_file_format/gen_DE_B18'\n",
    "\n",
    "# Create an empty DataFrame with columns\n",
    "columns = ['Reading time (s)', 'Storage space (KB)']\n",
    "df_comparison = pd.DataFrame(columns=columns)\n",
    "\n",
    "# Reading a trivial original data file\n",
    "df = pd.read_csv(f'{filepath}.csv', sep=',', decimal='.', encoding='utf-8')\n",
    "df.head(5)\n",
    "\n",
    "# Setting the correct types\n",
    "df.StartTime = pd.to_datetime(df.StartTime, format='%Y-%m-%dT%H:%M%zZ')\n",
    "df.EndTime = pd.to_datetime(df.EndTime, format='%Y-%m-%dT%H:%M%zZ')\n",
    "df.AreaID = df.AreaID.astype(str)\n",
    "df.UnitName = df.UnitName.astype(str)\n",
    "df.PsrType = df.PsrType.astype(str)\n",
    "df.quantity = df.quantity.astype(int)\n",
    "\n",
    "# Creating some test files\n",
    "compression_algorithms = ['none', 'snappy', 'gzip', 'brotli']\n",
    "df.to_csv(f'{filepath}_csv.csv', index = False, encoding = 'utf-8', sep = ',')\n",
    "for ca in compression_algorithms:\n",
    "    df.to_parquet(f'{filepath}_parquet_{ca}.parquet', index = False, engine = 'pyarrow', compression = ca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although we are duplicating data, for completion purposes we will store the CSV again and check some metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading the test files and storing the time\n",
    "start_time = time.time()\n",
    "df_csv = pd.read_csv(f'{filepath}.csv', sep=',', decimal='.', encoding='utf-8')\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate reading time\n",
    "reading_time = end_time - start_time\n",
    "    \n",
    "# Get file size in KB\n",
    "file_size_bytes = os.path.getsize(f'{filepath}.csv')\n",
    "file_size_kb = file_size_bytes / 1024  # Convert bytes to KB\n",
    "\n",
    "comparison_data = []\n",
    "\n",
    "# Appending data to the comparison dictionary\n",
    "comparison_data.append({\n",
    "    'File format': 'CSV',\n",
    "    'Reading time (s)': reading_time,\n",
    "    'Storage space (KB)': file_size_kb\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also check some metrics for the parquet format using different compression algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>File format</th>\n",
       "      <th>Reading time (s)</th>\n",
       "      <th>Storage space (KB)</th>\n",
       "      <th>Ratio (seconds)/(KB)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CSV</td>\n",
       "      <td>0.034355</td>\n",
       "      <td>2659.800781</td>\n",
       "      <td>0.000013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Parquet - none</td>\n",
       "      <td>0.034975</td>\n",
       "      <td>796.294922</td>\n",
       "      <td>0.000044</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parquet - snappy</td>\n",
       "      <td>0.005335</td>\n",
       "      <td>718.826172</td>\n",
       "      <td>0.000007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Parquet - gzip</td>\n",
       "      <td>0.005535</td>\n",
       "      <td>571.174805</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parquet - brotli</td>\n",
       "      <td>0.004627</td>\n",
       "      <td>499.117188</td>\n",
       "      <td>0.000009</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        File format  Reading time (s)  Storage space (KB)  \\\n",
       "0               CSV          0.034355         2659.800781   \n",
       "1    Parquet - none          0.034975          796.294922   \n",
       "2  Parquet - snappy          0.005335          718.826172   \n",
       "3    Parquet - gzip          0.005535          571.174805   \n",
       "4  Parquet - brotli          0.004627          499.117188   \n",
       "\n",
       "   Ratio (seconds)/(KB)  \n",
       "0              0.000013  \n",
       "1              0.000044  \n",
       "2              0.000007  \n",
       "3              0.000010  \n",
       "4              0.000009  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Iterating over the different parquet options\n",
    "for ca in compression_algorithms:\n",
    "    file = f'{filepath}_parquet_{ca}.parquet'\n",
    "        \n",
    "    start_time = time.time()\n",
    "    df = pd.read_parquet(file, engine = 'pyarrow')\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate reading time\n",
    "    reading_time = end_time - start_time\n",
    "    \n",
    "    # Get file size in KB\n",
    "    file_size_bytes = os.path.getsize(file)\n",
    "    file_size_kb = file_size_bytes / 1024  # Convert bytes to KB\n",
    "    \n",
    "    # Append data to the comparison dictionary\n",
    "    comparison_data.append({\n",
    "        'File format': f'Parquet - {ca}',\n",
    "        'Reading time (s)': reading_time,\n",
    "        'Storage space (KB)': file_size_kb\n",
    "    })\n",
    "\n",
    "# Create a DataFrame from the list of dictionaries\n",
    "df_comparison = pd.DataFrame(comparison_data)\n",
    "\n",
    "df_comparison['Ratio (seconds)/(KB)'] = df_comparison['Reading time (s)']/df_comparison['Storage space (KB)']\n",
    "df_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this small example, we can see how CSV is greatly inferior in terms of both reading speed and storage space. In addition, parquet stores the types of the different columns, so there is no apparent downside to using it for this project. In particular we have decided to use snappy as it has a better ratio compared to the other checked options."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
